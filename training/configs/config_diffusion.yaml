# Configuration for training diffusion transformer

model:
  embedding_dim: 512
  nhead: 8
  num_encoder_layers: 6
  dropout: 0.1

training:
  learning_rate: 1e-4
  batch_size: 16
  num_epochs: 50
  save_interval: 10

data:
  audio_dir: "data/processed/audio"  # Path to preprocessed audio data
  video_dir: "data/processed/video"  # Path to preprocessed video frames

output:
  model_save_path: "output/models/diffusion"  # Path to save models
  log_dir: "output/logs/diffusion"  # Path to save logs
